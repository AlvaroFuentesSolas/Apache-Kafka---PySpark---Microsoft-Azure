# Apache Kafka - PySpark - Microsoft Azure

These processes consist of the analysis, transformations and incremental updates of the data as they are received by Apache Kafka in search of the results we want in our case. We receive the streaming data from Apache Kafka and by means of Apache Spark we select and specify the information by means of queries, in a determined interval of time. The results are inserted into SQL tables in Azure Microsoft created for this specific data.
